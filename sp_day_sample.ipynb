{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Simple Notebook Using ODW Newspaper data**\n\nWith kudos to [jcoliver's](https://github.com/jcoliver) [Collections as Data](repository). This is a slight variation on the [Introduction to text mining notebook](https://github.com/jcoliver/dig-coll-borderlands/blob/main/Text-Mining-Short.ipynb).","metadata":{},"id":"5d03b751-1996-4d0e-812e-3703061a7ea1"},{"cell_type":"code","source":"# First step is to get all of the necessary python building blocks\nimport pandas\n\n# for file navigation\nimport os\n\n# for text data mining\nimport nltk\n\n# for stopword corpora for a variety of languages\nfrom nltk.corpus import stopwords\n\n# for splitting data into individual words\nfrom nltk.tokenize import RegexpTokenizer\n\n# download the stopwords for several languages\nnltk.download('stopwords')\n\n# for drawing the plot\nimport plotly.express as px\n\n# custom module from U of Arizona\nimport digcol","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"9c8b4dfa-82df-4a71-93b1-bbad475547c1"},{"cell_type":"markdown","source":"You need to run the block above for the one below to work. The notebook will need all of the libraries it imports. The next block is where the newspaper is specfied.","metadata":{},"id":"25e92871-353e-4fb0-9feb-8c916169ee9a"},{"cell_type":"code","source":"newspaper = 'echo' #code for the Amherstburg Echo\nlanguage = 'english' #needs to match stopwords from jovyan\ntopic_words = ['influenza'] #simple catch-all for demo","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"219d97cc-9a83-4406-9caf-ac5da04a6b97"},{"cell_type":"markdown","source":"The data can now be accessed in the notebook.","metadata":{},"id":"906c1b69-e0cb-4898-9d2c-6ea1d78f9663"},{"cell_type":"code","source":"# only one data path at this point\nvolume_path = 'data_samples'\n\nsample_issues = os.listdir(newspaper)\nsample_issues.sort()\n\ndates = []\nfor issue in sample_issues:\n    dates.append(issue[0:10])\n\n# Add those dates to a data frame\nresults_table = pandas.DataFrame(dates, columns = ['Date'])\n\n# Set all frequencies to zero\nresults_table['Frequency'] = 0.0\n\n# Cycle over all issues and do relative frequency calculations\nfor issue in sample_issues:\n    issue_text = digcol.CleanText(filename = newspaper + '/' + issue, language = language)\n    issue_text = issue_text.clean_list\n    \n    # Create a table with words\n    word_table = pandas.Series(issue_text)\n\n    # Calculate relative frequencies of all words in the issue\n    word_freqs = word_table.value_counts(normalize = True)\n    \n    # Pull out only values that match words of interest\n    my_freqs = word_freqs.filter(topic_words)\n    \n    # Get the total frequency for words of interest\n    total_my_freq = my_freqs.sum()\n    \n    # Format the date from the name of the file so we know where to put\n    # the data in our table\n    issue_date = str(issue[0:10])\n    \n    # Add the date & relative frequency to our data table\n    results_table.loc[results_table['Date'] == issue_date, 'Frequency'] = total_my_freq\n    \n# Analyses are all done, plot the figure\nmy_figure = px.line(results_table, x = 'Date', y = 'Frequency')\nmy_figure.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7db046dc-751b-4dd9-ae25-e4b787a61a4e"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"2347e782-47d3-4f92-972f-86d3ffbd6004"}]}
